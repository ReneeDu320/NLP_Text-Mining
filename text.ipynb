{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use nlp for text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#load data\n",
    "data = pd.read_csv(\"data_trian.csv\")\n",
    "data.head()\n",
    "#remove special characters\n",
    "data['text']=data['text'].str.replace(\"[^a-zA-Z#]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(data['text'], data['class'],test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9436,) (2360,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8355     tourist trap  can t believe so many people fal...\n",
       "5293     This was my first time there and I was not dis...\n",
       "988      Frankly  I am torn between if I should give th...\n",
       "4669     Yelp needs to update the address of this place...\n",
       "11464    First time eating French food  Wow amazing hol...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_x.shape, test_x.shape)\n",
    "train_x.head()\n",
    "test_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/karen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    " use TfidfVectorizer() and CountVectorizer() for feather extraction, and apply the feathers into different models\n",
    "'''\n",
    "#Use TF-IDF to extract features and vectorize sentences after word segmentation.\n",
    "#import nltk package\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "TF_Vec=TfidfVectorizer(max_df=0.8,\n",
    "                       min_df = 3,\n",
    "                       stop_words=frozenset(stop_words)\n",
    "                      )\n",
    "#data fitting, transform the data into standard form (usually used in traning set)\n",
    "train_x_tfvec=TF_Vec.fit_transform(train_x)\n",
    "#Standardization through centralization and scaling (used in test sets)\n",
    "test_x_tfvec=TF_Vec.transform(test_x)\n",
    " \n",
    "#Start using CountVectorizer() for feature extraction. It transforms vectors according to the frequency of words. \n",
    "CT_Vec=CountVectorizer(max_df=0.8,#remove the words appear more than 80%\n",
    "                       min_df = 3,#remove the words appear less than 3 times\n",
    "                       token_pattern=u'(?u)\\\\b[^\\\\d\\\\W]\\\\w+\\\\b',#Use regular expressions \n",
    "                       stop_words=frozenset(stop_words))#add stop words\n",
    "#data fitting, transform the data into standard form (usually used in traning set)\n",
    "train_x_ctvec=CT_Vec.fit_transform(train_x)\n",
    "#Standardization through centralization and scaling (used in test sets)\n",
    "test_x_ctvec=CT_Vec.transform(test_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameter： {'C': 1.0, 'penalty': 'l2'}\n",
      "Use TF-IDF for feature extraction; use logistic regression to find the optimal model\n",
      "training set:0.7928147520135651\n",
      "test set:0.6826271186440678\n",
      "the run time of optimized model 51.10105776786804\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "using TF_IDF to extracting data features \n",
    "'''\n",
    "#import package\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "start_time=time.time()\n",
    "#create model\n",
    "lr = linear_model.LogisticRegression(penalty='l2', C=1, solver='liblinear', max_iter=1000, multi_class='ovr')\n",
    "#Optimize the model, because some parameters are uncertain, so let the model determine its own parameters during training \n",
    "# The name of the model is also changed from LR to model\n",
    "model = GridSearchCV(lr, cv=3, param_grid={\n",
    "        'C': np.logspace(0, 4, 30), # logspace(a,b,n) generates n points between decades 10^a and 10^b.\n",
    "        'penalty': ['l1', 'l2']\n",
    "    })\n",
    "#模型拟合tf-idf拿到的数据\n",
    "model.fit(train_x_tfvec,train_y)\n",
    "#find optimal parameter\n",
    "print('optimal parameter：', model.best_params_)\n",
    "#accuracy rate on train set before training\n",
    "pre_train_y=model.predict(train_x_tfvec)\n",
    "#accuracy score on train set\n",
    "train_accracy=accuracy_score(pre_train_y,train_y)\n",
    "#View predictions at the end of training \n",
    "pre_test_y=model.predict(test_x_tfvec)\n",
    "#accuracy score on test set\n",
    "test_accracy = accuracy_score(pre_test_y,test_y)\n",
    "print('Use TF-IDF for feature extraction; use logistic regression to find the optimal model\\ntraining set:{0}\\ntest set:{1}'.format(train_accracy,test_accracy))\n",
    "end_time=time.time()\n",
    "print(\"the run time of optimized model\",end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameter： {'C': 1.0, 'penalty': 'l1'}\n",
      "Use CountVectorizer for feather extraction, use logistic regression to find the optimal model\n",
      "training set:0.869118270453582\n",
      "test set:0.6538135593220339\n",
      "The runtime of optimized model 59.386225938797\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "use CountVectorizer to extracting data features \n",
    "'''\n",
    "#import package\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "start_time=time.time()\n",
    "#create model\n",
    "lr = linear_model.LogisticRegression(penalty='l2', C=1, solver='liblinear', max_iter=1000, multi_class='ovr')\n",
    "\n",
    "model = GridSearchCV(lr, cv=3, param_grid={\n",
    "        'C': np.logspace(0, 4, 30),\n",
    "        'penalty': ['l1', 'l2']\n",
    "    })\n",
    "#Model fitting using CountVectorizer\n",
    "model.fit(train_x_ctvec,train_y)\n",
    "#find optimal parameter\n",
    "print('optimal parameter：', model.best_params_)\n",
    "#check accuracy rate \n",
    "pre_train_y=model.predict(train_x_ctvec)\n",
    "\n",
    "train_accracy=accuracy_score(pre_train_y,train_y)\n",
    "\n",
    "pre_test_y=model.predict(test_x_ctvec)\n",
    "\n",
    "test_accracy = accuracy_score(pre_test_y,test_y)\n",
    "print('Use CountVectorizer for feather extraction, use logistic regression to find the optimal model\\ntraining set:{0}\\ntest set:{1}'.format(train_accracy,test_accracy))\n",
    "end_time=time.time()\n",
    "print(\"The runtime of optimized model\",end_time-start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use other machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use TfidfVectorizer for feature extraction, use KNN classifier, the accuracy rate is:\n",
      "training set:0.511551504874947\n",
      "test set:0.4775423728813559\n",
      "The runtime of KNN classifier is 7.416763782501221\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "start_time=time.time()\n",
    "#CREATE model\n",
    "Kn = KNeighborsClassifier()\n",
    "#fit model using the data from tf-idf\n",
    "Kn.fit(train_x_tfvec,train_y)\n",
    "pre_train_y=Kn.predict(train_x_tfvec)\n",
    "train_accracy=accuracy_score(pre_train_y,train_y)\n",
    "pre_test_y=Kn.predict(test_x_tfvec)\n",
    "test_accracy = accuracy_score(pre_test_y,test_y)\n",
    "print('Use TfidfVectorizer for feature extraction, use KNN classifier, the accuracy rate is:\\ntraining set:{0}\\ntest set:{1}'.format(train_accracy,test_accracy))\n",
    "end_time=time.time()\n",
    "print(\"The runtime of KNN classifier is\",end_time-start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use CounterfVectorizer for feature extraction; use Random Forest Classifier; the accuracy rate is\n",
      "training set:0.9992581602373887\n",
      "test set:0.6813559322033899\n",
      "The runtime of Random Forest Classififer is 10.78722596168518\n"
     ]
    }
   ],
   "source": [
    "### Random Forest Classifier \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "import time\n",
    "start_time=time.time()\n",
    "#create model\n",
    "Rfc = RandomForestClassifier(n_estimators=100)\n",
    "#fit the model using data from CounterfVectorizer\n",
    "Rfc.fit(train_x_ctvec,train_y)\n",
    "pre_train_y=Rfc.predict(train_x_ctvec)\n",
    "\n",
    "train_accracy=accuracy_score(pre_train_y,train_y)\n",
    "\n",
    "pre_test_y=Rfc.predict(test_x_ctvec)\n",
    "\n",
    "test_accracy = accuracy_score(pre_test_y,test_y)\n",
    "print('use CounterfVectorizer for feature extraction; use Random Forest Classifier; the accuracy rate is\\ntraining set:{0}\\ntest set:{1}'.format(train_accracy,test_accracy))\n",
    "end_time=time.time()\n",
    "print(\"The runtime of Random Forest Classififer is\",end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use tffor feature extraction, use decision tree classifier, the accuracy is:\n",
      "training set:0.9992581602373887\n",
      "test set:0.6813559322033899\n",
      "the runtime of decision tree classifier is: 2.791985034942627\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "from sklearn import tree\n",
    "import time\n",
    "start_time=time.time()\n",
    "#create model\n",
    "Rf = tree.DecisionTreeClassifier()\n",
    "#fit using data from tf-idf\n",
    "Rf.fit(train_x_tfvec,train_y)\n",
    "pre_train_y=Rf.predict(train_x_tfvec)\n",
    "train_accracy=accuracy_score(pre_train_y,train_y)\n",
    "test_accracy = accuracy_score(pre_test_y,test_y)\n",
    "print('use tffor feature extraction, use decision tree classifier, the accuracy is:\\ntraining set:{0}\\ntest set:{1}'.format(train_accracy,test_accracy))\n",
    "end_time=time.time()\n",
    "print(\"the runtime of decision tree classifier is:\",end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use CounterVectorizer for feature extraction, use Bayes Classifier, the accuracy rate is:\n",
      "training set:0.7658965663416702\n",
      "test set:0.6775423728813559\n",
      "The runtime of Bayes Classifier is 0.05059003829956055\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import time\n",
    "start_time=time.time()\n",
    "#create model\n",
    "Bys = MultinomialNB()\n",
    "Bys.fit(train_x_ctvec, train_y)\n",
    "pre_train_y=Bys.predict(train_x_ctvec)\n",
    "train_accracy=accuracy_score(pre_train_y,train_y)\n",
    "pre_test_y=Bys.predict(test_x_ctvec)\n",
    "test_accracy = accuracy_score(pre_test_y,test_y)\n",
    "print('use CounterVectorizer for feature extraction, use Bayes Classifier, the accuracy rate is:\\ntraining set:{0}\\ntest set:{1}'.format(train_accracy,test_accracy))\n",
    "end_time=time.time()\n",
    "print(\"The runtime of Bayes Classifier is\",end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use CounterfVectorizer for feature extraction, use SVM Classifier, the accuracy rate is:\n",
      "training set:0.6409495548961425\n",
      "test set:0.6161016949152542\n",
      "The runtime of SVM Classifier is: 68.90573620796204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import time\n",
    "start_time=time.time()\n",
    "SVM = SVC(C=1.0, kernel='rbf', gamma='auto')\n",
    "SVM.fit(train_x_ctvec, train_y)\n",
    "pre_train_y=SVM.predict(train_x_ctvec)\n",
    "train_accracy=accuracy_score(pre_train_y,train_y)\n",
    "pre_test_y=SVM.predict(test_x_ctvec)\n",
    "test_accracy = accuracy_score(pre_test_y,test_y)\n",
    "print('Use CounterfVectorizer for feature extraction, use SVM Classifier, the accuracy rate is:\\ntraining set:{0}\\ntest set:{1}'.format(train_accracy,test_accracy))\n",
    "end_time=time.time()\n",
    "print(\"The runtime of SVM Classifier is:\",end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The above results show that Decision Tree Classifier has the best performance over all models. The decision tree classifier has comparatively less runtime, but higher accuracy score on the test set."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eba38789ab565d76f074e8fa97ecc7da63eb4a5e1ba28cc348f16f5285783ca7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
