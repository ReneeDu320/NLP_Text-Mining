{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use nlp for text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#load data\n",
    "data = pd.read_csv(\"data_trian.csv\")\n",
    "data.head()\n",
    "#remove special characters\n",
    "data['text']=data['text'].str.replace(\"[^a-zA-Z#]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(data['text'], data['class'],test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9436,) (2360,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3881    We were promptly seated on a Friday night  Sta...\n",
       "2690    Fette Sau is deliciousness  This place is grea...\n",
       "28      I came here with a friend for restaurant week ...\n",
       "8037    This tiny  unassuming restaurant serves incred...\n",
       "9595    We had a birthday party in the library at the ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_x.shape, test_x.shape)\n",
    "train_x.head()\n",
    "test_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/karen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    " use TfidfVectorizer() and CountVectorizer() for feather extraction, and apply the feathers into different models\n",
    "'''\n",
    "#Use TF-IDF to extract features and vectorize sentences after word segmentation.\n",
    "#import nltk package\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "TF_Vec=TfidfVectorizer(max_df=0.8,\n",
    "                       min_df = 3,\n",
    "                       stop_words=frozenset(stop_words)\n",
    "                      )\n",
    "#data fitting, transform the data into standard form (usually used in traning set)\n",
    "train_x_tfvec=TF_Vec.fit_transform(train_x)\n",
    "#Standardization through centralization and scaling (used in test sets)\n",
    "test_x_tfvec=TF_Vec.transform(test_x)\n",
    " \n",
    "#Start using CountVectorizer() for feature extraction. It transforms vectors according to the frequency of words. \n",
    "CT_Vec=CountVectorizer(max_df=0.8,#remove the words appear more than 80%\n",
    "                       min_df = 3,#remove the words appear less than 3 times\n",
    "                       token_pattern=u'(?u)\\\\b[^\\\\d\\\\W]\\\\w+\\\\b',#Use regular expressions \n",
    "                       stop_words=frozenset(stop_words))#add stop words\n",
    "#data fitting, transform the data into standard form (usually used in traning set)\n",
    "train_x_ctvec=CT_Vec.fit_transform(train_x)\n",
    "#Standardization through centralization and scaling (used in test sets)\n",
    "test_x_ctvec=CT_Vec.transform(test_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameter： {'C': 1.0, 'penalty': 'l2'}\n",
      "Use TF-IDF for feather extraction; use logistic regression to find the optimal model\n",
      "training set:0.7928147520135651\n",
      "testing set:0.6826271186440678\n",
      "the run time of optimized model 48.23542284965515\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "using TF_IDF to extracting data features \n",
    "'''\n",
    "#import package\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "start_time=time.time()\n",
    "#create model\n",
    "lr = linear_model.LogisticRegression(penalty='l2', C=1, solver='liblinear', max_iter=1000, multi_class='ovr')\n",
    "#Optimize the model, because some parameters are uncertain, so let the model determine its own parameters during training \n",
    "# The name of the model is also changed from LR to model\n",
    "model = GridSearchCV(lr, cv=3, param_grid={\n",
    "        'C': np.logspace(0, 4, 30), # logspace(a,b,n) generates n points between decades 10^a and 10^b.\n",
    "        'penalty': ['l1', 'l2']\n",
    "    })\n",
    "#模型拟合tf-idf拿到的数据\n",
    "model.fit(train_x_tfvec,train_y)\n",
    "#find optimal parameter\n",
    "print('optimal parameter：', model.best_params_)\n",
    "#accuracy rate on train set before training\n",
    "pre_train_y=model.predict(train_x_tfvec)\n",
    "#accuracy score on train set\n",
    "train_accracy=accuracy_score(pre_train_y,train_y)\n",
    "#View predictions at the end of training \n",
    "pre_test_y=model.predict(test_x_tfvec)\n",
    "#accuracy score on test set\n",
    "test_accracy = accuracy_score(pre_test_y,test_y)\n",
    "print('Use TF-IDF for feature extraction; use logistic regression to find the optimal model\\ntraining set:{0}\\ntesting set:{1}'.format(train_accracy,test_accracy))\n",
    "end_time=time.time()\n",
    "print(\"the run time of optimized model\",end_time-start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameter： {'C': 1.0, 'penalty': 'l1'}\n",
      "Use CountVectorizer for feather extraction,让模型自适应参数，进行模型优化\n",
      "训练集:0.869118270453582\n",
      "测试集:0.6546610169491526\n",
      "The runtime of optimized model 81.57314682006836\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "use CountVectorizer to extracting data features \n",
    "'''\n",
    "#import package\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "start_time=time.time()\n",
    "#create model\n",
    "lr = linear_model.LogisticRegression(penalty='l2', C=1, solver='liblinear', max_iter=1000, multi_class='ovr')\n",
    "\n",
    "model = GridSearchCV(lr, cv=3, param_grid={\n",
    "        'C': np.logspace(0, 4, 30),\n",
    "        'penalty': ['l1', 'l2']\n",
    "    })\n",
    "#Model fitting using CountVectorizer\n",
    "model.fit(train_x_ctvec,train_y)\n",
    "#find optimal parameter\n",
    "print('optimal parameter：', model.best_params_)\n",
    "#check accuracy rate \n",
    "pre_train_y=model.predict(train_x_ctvec)\n",
    "\n",
    "train_accracy=accuracy_score(pre_train_y,train_y)\n",
    "\n",
    "pre_test_y=model.predict(test_x_ctvec)\n",
    "\n",
    "test_accracy = accuracy_score(pre_test_y,test_y)\n",
    "print('Use CountVectorizer for feather extraction, use logistic regression to find the optimal model\\ntraining set:{0}\\ntesting set:{1}'.format(train_accracy,test_accracy))\n",
    "end_time=time.time()\n",
    "print(\"The runtime of optimized model\",end_time-start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use other machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use TfidfVectorizer for feature extraction, use KNN classifier, the accuracy rate is:\n",
      "train set:0.511551504874947\n",
      "test set:0.4775423728813559\n",
      "The runtime of KNN classifier is 7.582112073898315\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "start_time=time.time()\n",
    "#CREATE model\n",
    "Kn = KNeighborsClassifier()\n",
    "#fit model using the data from tf-idf\n",
    "Kn.fit(train_x_tfvec,train_y)\n",
    "pre_train_y=Kn.predict(train_x_tfvec)\n",
    "train_accracy=accuracy_score(pre_train_y,train_y)\n",
    "pre_test_y=Kn.predict(test_x_tfvec)\n",
    "test_accracy = accuracy_score(pre_test_y,test_y)\n",
    "print('Use TfidfVectorizer for feature extraction, use KNN classifier, the accuracy rate is:\\ntrain set:{0}\\ntest set:{1}'.format(train_accracy,test_accracy))\n",
    "end_time=time.time()\n",
    "print(\"The runtime of KNN classifier is\",end_time-start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use CounterfVectorizer for feature extraction; use Random Forest Classifier; the accuracy rate is\n",
      "train set:0.9992581602373887\n",
      "test set:0.6733050847457627\n",
      "The runtime of Random Forest Classififer is 10.090601921081543\n"
     ]
    }
   ],
   "source": [
    "### Random Forest Classifier \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "import time\n",
    "start_time=time.time()\n",
    "#create model\n",
    "Rfc = RandomForestClassifier(n_estimators=100)\n",
    "#fit the model using data from CounterfVectorizer\n",
    "Rfc.fit(train_x_ctvec,train_y)\n",
    "pre_train_y=Rfc.predict(train_x_ctvec)\n",
    "\n",
    "train_accracy=accuracy_score(pre_train_y,train_y)\n",
    "\n",
    "pre_test_y=Rfc.predict(test_x_ctvec)\n",
    "\n",
    "test_accracy = accuracy_score(pre_test_y,test_y)\n",
    "print('use CounterfVectorizer for feature extraction; use Random Forest Classifier; the accuracy rate is\\ntrain set:{0}\\ntest set:{1}'.format(train_accracy,test_accracy))\n",
    "end_time=time.time()\n",
    "print(\"The runtime of Random Forest Classififer is\",end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use tffor feature extraction, use decision tree classifier, the accuracy is:\n",
      "train set:0.9992581602373887\n",
      "test set:0.6775423728813559\n",
      "the runtime of decision tree classifier is: 2.900256872177124\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "from sklearn import tree\n",
    "import time\n",
    "start_time=time.time()\n",
    "#create model\n",
    "Rf = tree.DecisionTreeClassifier()\n",
    "#fit using data from tf-idf\n",
    "Rf.fit(train_x_tfvec,train_y)\n",
    "pre_train_y=Rf.predict(train_x_tfvec)\n",
    "train_accracy=accuracy_score(pre_train_y,train_y)\n",
    "test_accracy = accuracy_score(pre_test_y,test_y)\n",
    "print('use tffor feature extraction, use decision tree classifier, the accuracy is:\\ntrain set:{0}\\ntest set:{1}'.format(train_accracy,test_accracy))\n",
    "end_time=time.time()\n",
    "print(\"the runtime of decision tree classifier is:\",end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use CounterVectorizer for feature extraction, use Bayes Classifier, the accuracy rate is:\n",
      "train set:0.7658965663416702\n",
      "test set:0.6775423728813559\n",
      "The runtime of Bayes Classifier is 0.011792182922363281\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import time\n",
    "start_time=time.time()\n",
    "#create model\n",
    "Bys = MultinomialNB()\n",
    "Bys.fit(train_x_ctvec, train_y)# 学习,拟合模型\n",
    "pre_train_y=Bys.predict(train_x_ctvec)\n",
    "train_accracy=accuracy_score(pre_train_y,train_y)\n",
    "pre_test_y=Bys.predict(test_x_ctvec)\n",
    "test_accracy = accuracy_score(pre_test_y,test_y)\n",
    "print('use CounterVectorizer for feature extraction, use Bayes Classifier, the accuracy rate is:\\ntrain set:{0}\\ntest set:{1}'.format(train_accracy,test_accracy))\n",
    "end_time=time.time()\n",
    "print(\"The runtime of Bayes Classifier is\",end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use CounterfVectorizer for feature extraction, use SVM Classifier, the accuracy rate is:\n",
      "train set:0.6409495548961425\n",
      "test set:0.6161016949152542\n",
      "The runtime of SVM Classifier is: 72.01821112632751\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import time\n",
    "start_time=time.time()\n",
    "SVM = SVC(C=1.0, kernel='rbf', gamma='auto')\n",
    "SVM.fit(train_x_ctvec, train_y)\n",
    "pre_train_y=SVM.predict(train_x_ctvec)\n",
    "train_accracy=accuracy_score(pre_train_y,train_y)\n",
    "pre_test_y=SVM.predict(test_x_ctvec)\n",
    "test_accracy = accuracy_score(pre_test_y,test_y)\n",
    "print('Use CounterfVectorizer for feature extraction, use SVM Classifier, the accuracy rate is:\\ntrain set:{0}\\ntest set:{1}'.format(train_accracy,test_accracy))\n",
    "end_time=time.time()\n",
    "print(\"The runtime of SVM Classifier is:\",end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The above results show that Decision Tree Classifier has the best performance over all models. The decision tree classifier has comparatively less runtime, but higher accuracy score on both train set and test set."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eba38789ab565d76f074e8fa97ecc7da63eb4a5e1ba28cc348f16f5285783ca7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
